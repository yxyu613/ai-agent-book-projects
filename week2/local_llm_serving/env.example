# Configuration for Tool Calling Demo
# Copy this file to .env and customize as needed

# Model Configuration (for vLLM)
MODEL_NAME=Qwen/Qwen3-0.6B
# Optional: Path to local model (if you've downloaded it)
# MODEL_PATH=/path/to/local/model

# vLLM Server Configuration (if using GPU)
VLLM_HOST=localhost
VLLM_PORT=8000

# Logging
LOG_LEVEL=INFO
