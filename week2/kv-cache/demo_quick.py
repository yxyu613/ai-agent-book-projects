#!/usr/bin/env python3
"""
Quick demonstration of KV cache impact
Shows the difference between correct and incorrect implementations
"""

import os
import sys
from agent import KVCacheAgent, KVCacheMode

def main():
    """Run a quick demo comparing correct vs incorrect implementation"""
    
    # Get API key
    api_key = os.getenv("MOONSHOT_API_KEY")
    if not api_key:
        print("‚ùå Please set MOONSHOT_API_KEY environment variable")
        print("   export MOONSHOT_API_KEY='your-api-key-here'")
        sys.exit(1)
    
    print("üöÄ KV Cache Quick Demo")
    print("="*60)
    
    # Simple task that requires multiple tool calls
    task = """Please do the following:
    1. Find all Python files in the week1 directory
    2. Read the main.py file from the context project
    3. Search for the word 'agent' in week1 files
    4. Provide a brief summary of what you found"""
    
    print(f"üìù Task: {task}")
    print("="*60)
    
    # Test 1: Correct implementation
    print("\n‚úÖ Testing CORRECT implementation (with KV cache)...")
    print("-"*60)
    agent_correct = KVCacheAgent(
        api_key=api_key,
        mode=KVCacheMode.CORRECT,
        root_dir="../..",
        verbose=False  # Set to True for detailed logs
    )
    
    result_correct = agent_correct.execute_task(task, max_iterations=10)
    metrics_correct = result_correct["metrics"]
    
    print(f"‚úì TTFT: {metrics_correct.ttft:.3f}s")
    print(f"‚úì Total Time: {metrics_correct.total_time:.3f}s")
    print(f"‚úì Cached Tokens: {metrics_correct.cached_tokens:,}")
    print(f"‚úì Cache Hits: {metrics_correct.cache_hits}")
    print(f"‚úì Total Tokens Used: {metrics_correct.prompt_tokens + metrics_correct.completion_tokens:,}")
    
    # Test 2: Incorrect implementation (dynamic system prompt)
    print("\n‚ùå Testing INCORRECT implementation (dynamic system prompt)...")
    print("-"*60)
    agent_incorrect = KVCacheAgent(
        api_key=api_key,
        mode=KVCacheMode.DYNAMIC_SYSTEM,
        root_dir="../..",
        verbose=False
    )
    
    result_incorrect = agent_incorrect.execute_task(task, max_iterations=10)
    metrics_incorrect = result_incorrect["metrics"]
    
    print(f"‚úó TTFT: {metrics_incorrect.ttft:.3f}s")
    print(f"‚úó Total Time: {metrics_incorrect.total_time:.3f}s")
    print(f"‚úó Cached Tokens: {metrics_incorrect.cached_tokens:,}")
    print(f"‚úó Cache Hits: {metrics_incorrect.cache_hits}")
    print(f"‚úó Total Tokens Used: {metrics_incorrect.prompt_tokens + metrics_incorrect.completion_tokens:,}")
    
    # Comparison
    print("\nüìä Performance Impact:")
    print("="*60)
    
    ttft_diff = ((metrics_incorrect.ttft - metrics_correct.ttft) / metrics_correct.ttft) * 100
    time_diff = ((metrics_incorrect.total_time - metrics_correct.total_time) / metrics_correct.total_time) * 100
    cache_lost = metrics_correct.cached_tokens - metrics_incorrect.cached_tokens
    
    print(f"‚ö° TTFT increased by: {ttft_diff:.1f}%")
    print(f"‚è±Ô∏è  Total time increased by: {time_diff:.1f}%")
    print(f"üíæ Cache tokens lost: {cache_lost:,}")
    
    if ttft_diff > 50:
        print("\n‚ö†Ô∏è  Dynamic system prompts severely impact performance!")
        print("   Even small context changes can invalidate the entire KV cache.")
    
    print("\nüí° Key Takeaway:")
    print("   Maintaining stable context is crucial for LLM performance.")
    print("   Small implementation details can have major performance impacts!")

if __name__ == "__main__":
    main()
